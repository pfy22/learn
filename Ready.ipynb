{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CUDAPluggableAllocator',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'Optional',\n",
       " 'OutOfMemoryError',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_DeviceGuard',\n",
       " '_LazySeedTracker',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_count_nvml',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_exchange_device',\n",
       " '_get_device_index',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_compiled',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_memory_viz',\n",
       " '_nvml_based_avail',\n",
       " '_parse_visible_devices',\n",
       " '_queued_calls',\n",
       " '_raw_device_count_nvml',\n",
       " '_raw_device_uuid_nvml',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_transform_uuid_to_ordinals',\n",
       " '_utils',\n",
       " '_warn_typed_storage_removal',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'can_device_access_peer',\n",
       " 'cast',\n",
       " 'change_current_allocator',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'contextlib',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'get_allocator_backend',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_current_stream_capturing',\n",
       " 'is_initialized',\n",
       " 'jiterator',\n",
       " 'list_gpu_processes',\n",
       " 'lru_cache',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看cuda的属性（变量）和方法（函数）\n",
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU数量\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看当前GPU序号 \n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU详细型号，输入要查的GPU型号\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2267, -1.2464,  0.6364, -1.2393],\n",
       "        [-0.3480, -0.0792, -0.8374, -0.2874],\n",
       "        [-1.0666, -1.0328, -0.8544, -0.5399],\n",
       "        [ 1.0383,  1.8177,  0.4158, -0.1728]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高斯随机分布的二维张量\n",
    "b = torch.randn(4, 4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2783, 0.8520, 0.4123, 0.8914],\n",
       "        [0.8886, 0.2220, 0.6906, 0.1864],\n",
       "        [0.0119, 0.8056, 0.6161, 0.4236],\n",
       "        [0.1252, 0.2172, 0.6698, 0.6132]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.rand(4, 4)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5049,  0.6056,  2.0487,  0.6521],\n",
       "        [ 1.5406,  1.1428,  0.8531,  0.8990],\n",
       "        [-0.0547,  0.7728,  0.7617,  0.8838],\n",
       "        [ 2.1635,  3.0349,  2.0856,  1.4404]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a + b + c\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:0')\n",
      "b = tensor([[ 0.2267, -1.2464,  0.6364, -1.2393],\n",
      "        [-0.3480, -0.0792, -0.8374, -0.2874],\n",
      "        [-1.0666, -1.0328, -0.8544, -0.5399],\n",
      "        [ 1.0383,  1.8177,  0.4158, -0.1728]], device='cuda:0')\n",
      "c = tensor([[0.2783, 0.8520, 0.4123, 0.8914],\n",
      "        [0.8886, 0.2220, 0.6906, 0.1864],\n",
      "        [0.0119, 0.8056, 0.6161, 0.4236],\n",
      "        [0.1252, 0.2172, 0.6698, 0.6132]], device='cuda:0')\n",
      "d = tensor([[ 1.5049,  0.6056,  2.0487,  0.6521],\n",
      "        [ 1.5406,  1.1428,  0.8531,  0.8990],\n",
      "        [-0.0547,  0.7728,  0.7617,  0.8838],\n",
      "        [ 2.1635,  3.0349,  2.0856,  1.4404]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 把数据导到GPU上\n",
    "a = a.to(\"cuda:0\")\n",
    "b = b.to(\"cuda:0\")\n",
    "c = c.to(\"cuda:0\")\n",
    "d = d.to(\"cuda:0\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"c = {c}\")\n",
    "print(f\"d = {d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
